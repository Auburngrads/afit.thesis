#analysis required libraries
library(sas7bdat)
library(fpp2)
library(zoo)
library(lubridate)
library(reshape2)
library(knitr)
library(gridExtra)
library(tidyverse)
library(kableExtra)
#template req'd libraries
library(knitcitations)
library(RefManageR)
library(xtable)
source('scripts/R/setup.R')
BIB <- ReadBib('references/my_bib.bib')
knitcitations <- BIB[title = 'knitcitations']
refmanager    <- BIB[title = 'RefManageR']
pressure      <- BIB[key = 'randolph2016']
cite_options(citation_format = 'pandoc')
# set directory for lazy data referencing
setwd("~/Documents/Grad School/Thesis/github/afit.thesis/Data")
# Here we read in all our data and combine the relevant sets for something workable
# Personnel Data
afsc_list <- read.sas7bdat("lu_ao_afs.sas7bdat")
assigned <- read.sas7bdat("assigned_levels.sas7bdat") %>%
spread(AFS, Assigned)
attrition <- read.sas7bdat("separations_count.sas7bdat") %>%
spread(AFS, Separation_Count)
# The dates in the personnel data are in total days since 1 Jan 1960 (SAS default)
# We'll need to reformat the date into something readable and mergeable with our
# econ set. Also, we create a new column - the total number of separations across
# all AFSCs. We'll also create totals for different categories of officers: rated,
# non-rated, line, etc.
attrition <- mutate(attrition, Total = rowSums(attrition[-1], na.rm = TRUE)) %>%
mutate(temp = EOP_Date * 86400) %>%
mutate(Date = as.POSIXct(temp, origin = "1960-01-01")) %>%
within(rm(temp, EOP_Date))
# repeat prodcedure for assigned data
assigned <- mutate(assigned, Total = rowSums(assigned[-1], na.rm = TRUE)) %>%
mutate(temp = EOP_Date * 86400) %>%
mutate(Date = as.POSIXct(temp, origin = "1960-01-01")) %>%
within(rm(temp, EOP_Date))
# Econ Data
econ_data <- list.files(pattern = "*_natl.csv") %>%
# Import data sets
lapply(read_csv) %>%
# Merge all sets
Reduce(function(x,y) merge(x, y, by = "DATE"), .) %>%
# Store data as tibble
as.tibble()
# Now, because gdp per cap is observed only on a quarterly basis, we add it separately
# in order to handle the missing values resulting from a merge. This merge is
# from the previous in that it keeps all values from the existing data set, creating NAs
# where gdp_per_cap does not match with other observations. Merging the quarterly
# gdp_per_cap data with the monthly indicators results in NAs in gdp_per_cap where
# the dates do not match. We then handle NAs by extending the quarterly records throughout
# their respective quarters (e.g. the GDP per cap for Q1 2014 is applied to Jan-Mar 2014).
# Simultaneously, we will rename the variables for interpretability.
# Read in GDP per capita
gdp_per_cap <- read_csv("real09_gdp_percap.csv")
# Combine gdp per cap with econ_data, using a left-join (all.x = TRUE) to preserve the main data set
econ_data <- merge(econ_data, gdp_per_cap, by = "DATE", all.x = TRUE) %>%
as.tibble() %>%
# Rename column headers to something more meaningful
select(Unemployment.Rate.Adj = UNRATE, Unemployment.Rate.NonAdj = UNRATENSA,
CPI.Adj = CPIAUCSL, Nonfarm.Jobs.Adj = JTSJOL,
Nonfarm.Jobs.NonAdj = JTUJOL, Labor.Force.Participation = LNS11327662,
Labor.Market.Momentum = FRBKCLMCIM, Real.GDP.Per.Capita = A939RX0Q048SBEA,
Nonfarm.Quits.Adj = JTSQUL, Date = DATE)
# The na.locf() command below carries a value forward through NAs until the next non-empty value is met;
# this is how we choose to represent the gdp per capita through an entire quarter
econ_data$Real.GDP.Per.Capita <- as.numeric(econ_data$Real.GDP.Per.Capita) %>%
na.locf()
# However, the date variables differ slightly between the econ and personnel sets:
# Though both represent monthly observations, the econ set default to the first
# of each month, and the personnel data defaulted to the last
# (e.g. October 2004 is represented as 01-10-2004 in the former, and 31-10-2004 in the latter)
# To handle this, we'll create new date variables in each set that have the days
# trimmed off, then merge. Merging isn't strictly necessary, but it is a convenient
# way to only keep those observations common to both data sets.
econ_data <- mutate(econ_data, "Date1" = paste(year(Date), month(Date)))
attrition <- mutate(attrition, "Date1" = paste(year(Date), month(Date)))
# Merge data
df <- merge(econ_data, attrition, by = "Date1")
# Next, we see many NAs within the attrition data set. Given the data's nature,
# our intuition was that these missing values aren't a result of encoding error
# or similar, but rather an indication that no separations occurred during
# that period (i.e. NAs indicate no separations were observed, instead of
# indicating some sort of error). This intuition was confirmed by the data's
# provider, HAF/A1FPX.
df[is.na(df)] <- 0
# Next we'll go ahead and drop all of our date variables. When we use df
# to create a time series object, the date variables become redundant.
df <- df[, !(names(df) %in% c("Date1", "Date.x", "Date.y"))]
# Now we'll initialize the time series object - start = Oct 2004, freq = 12 -
# and create the validation and training sets. Since we're only really interested
# in the Total column for modeling purposes
df.ts.1 <- ts(df, start = c(2004, 10), frequency = 12)
train.ts.1 <- subset(df.ts.1, end = 127)
val.ts.1 <- subset(df.ts.1, start = 128)
# subset LFPR and unemployment, then graph to reinforce a point made above
# data.frame("LFPR" = combined_1[,"Labor.Force.Participation"],
#            "Unemployment Rate" = combined_1[,"Unemployment.Rate.Adj"]) %>%
df.ts.1[,c("Labor.Force.Participation", "Unemployment.Rate.Adj")] %>%
autoplot(facets = TRUE) +
geom_smooth(size = .5, alpha = 0) +
scale_x_continuous(limits = c(2005, 2016), name = "Year") +
scale_y_continuous(name = "Percent of Population")
panderOptions('table.alignment.default',
function(df) ifelse(sapply(df, is.numeric), 'right', 'left'))
knitr::opts_chunk$set(echo = FALSE, show = FALSE, warning = FALSE, message = FALSE, cache = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
x <- def.chunk.hook(x, options)
ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
#check for req'd packages, will be installed automatically if not present
list.of.packages <- c("tidyverse", "lubridate", "sas7bdat", "fpp2", "reshape2",
"stargazer", "knitcitations", "RefManageR", "xtable",
"kableExtra", "zoo")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages, repos="http://cran.us.r-project.org")
# source file containing functions created for this analysis
source("~/Documents/Grad School/Thesis/github/afit.thesis/custom-functions.R")
#analysis required libraries
library(sas7bdat)
library(fpp2)
library(zoo)
library(lubridate)
library(reshape2)
library(knitr)
library(gridExtra)
library(tidyverse)
library(kableExtra)
#template req'd libraries
library(knitcitations)
library(RefManageR)
library(xtable)
source('scripts/R/setup.R')
BIB <- ReadBib('references/my_bib.bib')
knitcitations <- BIB[title = 'knitcitations']
refmanager    <- BIB[title = 'RefManageR']
pressure      <- BIB[key = 'randolph2016']
cite_options(citation_format = 'pandoc')
# set directory for lazy data referencing
setwd("~/Documents/Grad School/Thesis/github/afit.thesis/Data")
# Here we read in all our data and combine the relevant sets for something workable
# Personnel Data
afsc_list <- read.sas7bdat("lu_ao_afs.sas7bdat")
assigned <- read.sas7bdat("assigned_levels.sas7bdat") %>%
spread(AFS, Assigned)
attrition <- read.sas7bdat("separations_count.sas7bdat") %>%
spread(AFS, Separation_Count)
# The dates in the personnel data are in total days since 1 Jan 1960 (SAS default)
# We'll need to reformat the date into something readable and mergeable with our
# econ set. Also, we create a new column - the total number of separations across
# all AFSCs. We'll also create totals for different categories of officers: rated,
# non-rated, line, etc.
attrition <- mutate(attrition, Total = rowSums(attrition[-1], na.rm = TRUE)) %>%
mutate(temp = EOP_Date * 86400) %>%
mutate(Date = as.POSIXct(temp, origin = "1960-01-01")) %>%
within(rm(temp, EOP_Date))
# repeat prodcedure for assigned data
assigned <- mutate(assigned, Total = rowSums(assigned[-1], na.rm = TRUE)) %>%
mutate(temp = EOP_Date * 86400) %>%
mutate(Date = as.POSIXct(temp, origin = "1960-01-01")) %>%
within(rm(temp, EOP_Date))
# Econ Data
econ_data <- list.files(pattern = "*_natl.csv") %>%
# Import data sets
lapply(read_csv) %>%
# Merge all sets
Reduce(function(x,y) merge(x, y, by = "DATE"), .) %>%
# Store data as tibble
as.tibble()
# Now, because gdp per cap is observed only on a quarterly basis, we add it separately
# in order to handle the missing values resulting from a merge. This merge is
# from the previous in that it keeps all values from the existing data set, creating NAs
# where gdp_per_cap does not match with other observations. Merging the quarterly
# gdp_per_cap data with the monthly indicators results in NAs in gdp_per_cap where
# the dates do not match. We then handle NAs by extending the quarterly records throughout
# their respective quarters (e.g. the GDP per cap for Q1 2014 is applied to Jan-Mar 2014).
# Simultaneously, we will rename the variables for interpretability.
# Read in GDP per capita
gdp_per_cap <- read_csv("real09_gdp_percap.csv")
# Combine gdp per cap with econ_data, using a left-join (all.x = TRUE) to preserve the main data set
econ_data <- merge(econ_data, gdp_per_cap, by = "DATE", all.x = TRUE) %>%
as.tibble() %>%
# Rename column headers to something more meaningful
select(Unemployment.Rate.Adj = UNRATE, Unemployment.Rate.NonAdj = UNRATENSA,
CPI.Adj = CPIAUCSL, Nonfarm.Jobs.Adj = JTSJOL,
Nonfarm.Jobs.NonAdj = JTUJOL, Labor.Force.Participation = LNS11327662,
Labor.Market.Momentum = FRBKCLMCIM, Real.GDP.Per.Capita = A939RX0Q048SBEA,
Nonfarm.Quits.Adj = JTSQUL, Date = DATE)
# The na.locf() command below carries a value forward through NAs until the next non-empty value is met;
# this is how we choose to represent the gdp per capita through an entire quarter
econ_data$Real.GDP.Per.Capita <- as.numeric(econ_data$Real.GDP.Per.Capita) %>%
na.locf()
# However, the date variables differ slightly between the econ and personnel sets:
# Though both represent monthly observations, the econ set default to the first
# of each month, and the personnel data defaulted to the last
# (e.g. October 2004 is represented as 01-10-2004 in the former, and 31-10-2004 in the latter)
# To handle this, we'll create new date variables in each set that have the days
# trimmed off, then merge. Merging isn't strictly necessary, but it is a convenient
# way to only keep those observations common to both data sets.
econ_data <- mutate(econ_data, "Date1" = paste(year(Date), month(Date)))
attrition <- mutate(attrition, "Date1" = paste(year(Date), month(Date)))
# Merge data
df <- merge(econ_data, attrition, by = "Date1")
# Next, we see many NAs within the attrition data set. Given the data's nature,
# our intuition was that these missing values aren't a result of encoding error
# or similar, but rather an indication that no separations occurred during
# that period (i.e. NAs indicate no separations were observed, instead of
# indicating some sort of error). This intuition was confirmed by the data's
# provider, HAF/A1FPX.
df[is.na(df)] <- 0
# Next we'll go ahead and drop all of our date variables. When we use df
# to create a time series object, the date variables become redundant.
df <- df[, !(names(df) %in% c("Date1", "Date.x", "Date.y"))]
# Now we'll initialize the time series object - start = Oct 2004, freq = 12 -
# and create the validation and training sets. Since we're only really interested
# in the Total column for modeling purposes
df.ts.1 <- ts(df, start = c(2004, 10), frequency = 12)
train.ts.1 <- subset(df.ts.1, end = 127)
val.ts.1 <- subset(df.ts.1, start = 128)
# subset LFPR and unemployment, then graph to reinforce a point made above
# data.frame("LFPR" = combined_1[,"Labor.Force.Participation"],
#            "Unemployment Rate" = combined_1[,"Unemployment.Rate.Adj"]) %>%
df.ts.1[,c("Labor.Force.Participation", "Unemployment.Rate.Adj")] %>%
autoplot(facets = TRUE) +
geom_smooth(size = .5, alpha = 0) +
scale_x_continuous(limits = c(2005, 2016), name = "Year") +
scale_y_continuous(name = "Percent of Population")
vars <- data.frame(Variable = c('Labor Market Momentum Index', 'CPI',
'Nonfarm Jobs Openings', 'Real GDP per Capita',
'Nonfarm Job Quits', 'Unemployment Rate',
'Labor Force Participation Rate'),
Description = c('Compares current market conditions to long-run average',
'Weighted average price of a basket of goods and services',
'Unfilled positions at the end of the month in the nonfarm sector',
'Measure of economic output per person, adjusted for inflation',
'Voluntary separations from jobs in the nonfarm sector',
'Percentage of unemployed individuals in the labor force',
'Percentage of the population either employed or actively seeking work'))
kable(vars, format = "latex", booktabs = TRUE, caption = "Selected Economic Indicators") %>%
kable_styling(full_width = FALSE, latex_options = "scale_down") %>%
row_spec(0, bold = TRUE)
# pander(vars, split.cell = 70, split.table = Inf)
autoplot(df.ts.1[,'Total'], ylab = "Total Separations")
p <- ggseasonplot(df.ts.1[,'Total'], year.labels = TRUE, year.labels.left = TRUE) +
ylab("Total Separations") +
ggtitle("") +
theme(legend.position = "none")
p
n.1 <- naive(train.ts.1[,"Total"], h = dim(val.ts.1)[1])
sn.1 <- snaive(train.ts.1[,"Total"], h = dim(val.ts.1)[1])
n.1.error <- accuracy(n.1, val.ts.1[,"Total"])
sn.1.error <- accuracy(sn.1, val.ts.1[,"Total"])
p <- autoplot(n.1) +
autolayer(val.ts.1[,"Total"]) +
theme(legend.position = "none") +
ylab("") +
xlab("")
q <- autoplot(sn.1) +
autolayer(val.ts.1[,"Total"]) +
theme(legend.position = "none") +
ylab("") +
xlab("")
grid.arrange(p, q, nrow=2, left = "Total Attrition", bottom = "Time")
kable(n.1.error[,1:6], caption = "Naive Results", digits = 3, align = 'c')
kable(sn.1.error[,1:6], caption = 'Seasonal Naive Results', digits = 3, align = 'c')
# To handle these, we'll calculate the average values of all other years during
# months and replace the current values. First, let's create slices of our
# response containing the months we're concerned with - December and November.
# We also want to grab the correpsonding indices for updating our series later.
dec <- subset(df.ts.1[,'Total'], month = 12)
dec.ind <- which(cycle(df.ts.1[,'Total']) == 12)
nov <- subset(df.ts.1[,'Total'], month = 11)
nov.ind <- which(cycle(df.ts.1[,'Total']) == 11)
# oct <- subset(df.ts.1[,'Total'], month = 10)
# sep <- subset(df.ts.1[,'Total'], month = 9)
# Referring back to p, and combining the graphical insights with information
# from the data's sponsor, we assume that 2006, '07, and '14 are the years which
# saw the largest effects from the separation incentive programs - i.e. artificial
# attrition. Those correspond the the 3rd, 4th, and 11th indices. So now, we
# replace those observations with the average of the non-aberrant years.
dec[c(3,4,11)] <- mean(dec[-c(3,4,11)])
nov[c(3,4,11)] <- mean(nov[-c(3,4,11)])
# And finally, we place these values back into the original series.
df.ts.1[dec.ind, 'Total'] <- dec
df.ts.1[nov.ind, 'Total'] <- nov
autoplot(df.ts.1[,'Total'], ylab = "Total Separations")
ggseasonplot(df.ts.1[,'Total'], year.labels = TRUE, year.labels.left = TRUE) +
ylab("Total Separations") +
ggtitle("Seasonal Plot: Total Separations") +
theme(legend.position = "none")
# store split index
set.split <- 127
# New train and val sets
train.ts.2 <- subset(df.ts.1[,'Total'], end = set.split)
val.ts.2 <- subset(df.ts.1[,'Total'], start = set.split+1)
# Train models and generate errors
n.2 <- naive(train.ts.2, h = length(val.ts.2))
sn.2 <- snaive(train.ts.2, h = length(val.ts.2))
n.2.error <- accuracy(n.2, val.ts.2)
sn.2.error <- accuracy(sn.2, val.ts.2)
outlier.compare <- data_frame("Raw Data" = sn.1.error[,2],
"Imputed Data" = sn.2.error[,2])
row.names(outlier.compare) <- c("Training", "Validation")
kable(outlier.compare, row.names = TRUE, caption = "Seasonal Naive RMSE Comparison",
digits = 3, align = 'c')
autoplot(sn.2) +
autolayer(val.ts.2) +
theme(legend.position = "none") +
ylab("Total Attrition")
df[which(names(econ_data) %ni% c("Date", "Date1"))] %>%
cor() %>%
round(2) %>%
reorder.cormat() %>%
get.upper.tri() %>%
melt(na.rm = TRUE) %>%
ggplot(aes(Var2, Var1, fill = value)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Collinearity") +
theme_minimal() + # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1)) +
coord_fixed() +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 3) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal") +
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
# grab index of econ vars: LFPR, Unem.Adj, LMM
econ.vars <- which(names(df) %in% c("Labor.Force.Participation",
"Unemployment.Rate.Adj",
"Labor.Market.Momentum"))
# Now that we've selected our regressors, we need to check for stationarity. We're
# looking for evidence of non-zero trend, seasonality, etc.
autoplot(df.ts.1[,econ.vars], facets = TRUE) +
ylab("")
econ.vars.d <- diff(df.ts.1[,econ.vars])
autoplot(econ.vars.d, facets = TRUE) +
ylab("")
# Oh, yea - way better. Differenced, these variables look useable. Now while
# we're looking at differencing, we should look to see if our response also
# needs to be differenced. Remember, we have this:
# autoplot(df.ts.1[,"Total"]) +
#   ylab("Total Attrition")
# Hmm, nothing too crazy, actually - is there any statistical evidence
# for differencing?
# regular differencing
#ndiffs(df.ts.1[,"Total"])
# seasonal differencing
#nsdiffs(df.ts.1[,"Total"])
# Neat! However, before we can build the model, we have to account for the
# differencing performed on our regressors. With simple differencing, we lose
# the first observation, and so we remove the first observation from our
# response.
#head(df.ts.1[,"Total"])
#head(econ.vars.d[,1])
response.ts <- ts(df.ts.1[-1,"Total"], start = c(2004, 11), frequency = 12)
#head(response.ts)
# We also need to split up the econ vars into training and test sets
# store split index
set.split <- 126
# subset our response
train.ts.3 <- subset(response.ts, end = set.split)
val.ts.3 <- subset(response.ts, start = set.split+1)
# subset econ variables
econ.vars.d.train <- subset(econ.vars.d, end = set.split)
econ.vars.d.val <- subset(econ.vars.d, start = set.split+1)
# We'll utilize the auto arima function from fpp2
dyn.reg.1 <- auto.arima(train.ts.3, xreg = econ.vars.d.train, trace = TRUE,
stepwise = FALSE, approximation = FALSE)
# grab coefficients and s.e. from model
coeffs <- round(dyn.reg.1$coef, digits = 3)
stderr <- round(sqrt(diag(dyn.reg.1$var.coef)), digits = 3)
# create data table
estimates <- bind_rows(coeffs, stderr)
rownames(estimates) <- c("Coeff", "StdErr")
colnames(estimates) <- c("$\\theta_1$", "$\\theta_2$", "$\\theta_3$",
"$\\theta_4$", "$\\Phi_1$", "$\\beta_0$",
"$\\beta_1$", "$\\beta_2$", "$\\beta_3$")
kable(estimates, escape = FALSE, caption = "Estimated Coefficients - Initial Model",
align = 'c', digits = 3, booktabs = TRUE, format = "latex") %>%
kable_styling() %>%
row_spec(0, bold = TRUE)
# The first thing we'll want to check, after the model summary, is how our
# residuals behave. Do they appear to satisfy normality assumptions? Are there
# any outliers? Evidence of leftover autocorrelation? Essentially, we're
# checking to see if there's anything other than white noise in the error term.
# No - to all of the above. ACF plots look clean, raw residuals seem
# noisy, and also have a roughly normal distribution. Furthermore, a Ljung-Box
# test shows no evidence that the data aren't normal (p: 0.8121).
checkresiduals(dyn.reg.1, test = FALSE)
p <- Box.test(dyn.reg.1$residuals, lag = 24, type = "Lj", fitdf = 9)
box.results <- data_frame("Test type" = p$method,
"Test statistic" = round(p$statistic, digits = 3),
"p-value" = round(p$p.value, digits = 3))
kable(box.results, caption = "Initial Model - Autocorrelation Test")
# Let's generate some forecasts then
dyn.reg.1.f <- forecast(dyn.reg.1, xreg = econ.vars.d.val, h = 20)
# And then plot those forecasts over the actual data
autoplot(dyn.reg.1.f) +
autolayer(dyn.reg.1$fitted) +
autolayer(val.ts.3) +
theme(legend.position = "none") +
ylab("Total Attrition")
# We'll also take a look at some accuracy measures. According to RMSE and MASE,
# the dynamic regression model performs better than a seasonal naive estimation;
# that's good news - we're getting closer towards accurate forecasting.
dyn.reg.1.error <- accuracy(dyn.reg.1.f, val.ts.3)
err.compare <- data_frame("Simple Naive" = n.2.error[,2],
"Seasonal Naive" = sn.2.error[,2],
"Dynamic Regression" = dyn.reg.1.error[,2])
rownames(err.compare) <- c("Training", "Validation")
kable(err.compare, caption = "Model RMSE Comparison", align = 'c', digits = 3)
lag.results <- readRDS("lagResults.rds")
getwd()
lag.results <- readRDS("Data/lagResults.rds")
lag.results <- readRDS("Data/lagResults.rds")
lag.results
lag.results <- readRDS("Data/lagResults.rds")
kable(summary(lag.results[4:6]))
lag.results %>%
filter(lag.results[,"Validation.RMSE"] <= 156.4 &
lag.results[,"Training.RMSE"] <= 133.1 &
lag.results[,"AICc"] <= 1299) %>%
kable(format = "latex", booktabs = TRUE, caption = "High Performance Across All Criteria") %>%
kable_styling() %>%
row_spec(0, bold = TRUE)
lag.results %>%
filter(lag.results[,"Validation.RMSE"] <= 156.4 &
lag.results[,"Training.RMSE"] <= 133.1 &
lag.results[,"AICc"] <= 1299) %>%
kable(format = "latex", booktabs = TRUE, caption = "High Performance Across All Criteria") %>%
kable_styling(latex_options = "hold_position") %>%
row_spec(0, bold = TRUE)
lag.results %>%
filter(lag.results[,"Validation.RMSE"] <= 156.4 &
lag.results[,"Training.RMSE"] <= 133.1 &
lag.results[,"AICc"] <= 1299) %>%
kable(format = "latex", booktabs = TRUE, caption = "High Performance Across All Criteria") %>%
kable_styling(latex_options = "hold_position") %>%
row_spec(0, bold = TRUE)
inner_join(best.by.AICc, best.by.trainingRMSE)
inner_join(best.by.AICc, best.by.validationRMSE)
inner_join(best.by.trainingRMSE, best.by.validationRMSE)
inner_join(best.by.AICc, best.by.trainingRMSE)
best.by.AICc <- lag.results %>%
arrange(AICc) %>%
head(5)
best.by.trainingRMSE <- lag.results %>%
arrange(Training.RMSE) %>%
head(5)
best.by.validationRMSE <- lag.results %>%
arrange(Validation.RMSE) %>%
head(5)
rbind(best.by.AICc, best.by.trainingRMSE, best.by.validationRMSE) %>%
kable(format = "latex", booktabs = TRUE, caption = "Common High Performers") %>%
kable_styling(latex_options = "hold_position") %>%
row_spec(0, bold = TRUE) %>%
group_rows("Best by AICc", 1, 5) %>%
group_rows("Best by Training RMSE", 6, 10) %>%
group_rows("Best by Validation RMSE", 11, 15)
dyn.reg.2 <- readRDS("Data/dynReg2.rds")
broom::tidy(dyn.reg.2)[,2:3]
broom::tidy(dyn.reg.2)#[,2:3]
?row_spec
inner_join(best.by.AICc, best.by.trainingRMSE)
xreg.train <- cbind(UR.lag.train[,"lag24"],
LFPR.lag.train[,"lag18"],
LMM.lag.train[,"lag18"])
xreg.val <- cbind(UR.lag.val[,"lag24"],
LFPR.lag.val[,"lag18"],
LMM.lag.val[,"lag18"])
dyn.reg.6 <- auto.arima(train.ts.3,
xreg = xreg.train,
stepwise = FALSE,
approximation = FALSE)
saveRDS(dyn.reg.6, "dynReg6.rds")
lag.results.2 %>%
filter(lag.results.2[,"Validation.RMSE"] <= 151.8 &
lag.results.2[,"Training.RMSE"] <= 133.9 &
lag.results.2[,"AICc"] <= 1303)
inner_join(best.by.AICc.2, best.by.trainingRMSE.2)
inner_join(best.by.AICc.2, best.by.validationRMSE.2)
inner_join(best.by.trainingRMSE.2, best.by.validationRMSE.2)
top.models.3
lag.results.3 <- readRDS("Data/lagResults3.rds")
lag.results.3 %>%
filter(AICc == min(AICc))
lag.results.3 %>%
filter(AICc == min(AICc)) %>%
kable(format = "latex", booktabs = TRUE, caption = "Alternative Predictors - Best Model") %>%
kable_styling(latex_options = "hold_position") %>%
row_spec(0, bold = TRUE)
top.models.3
top.models.1
top.models.2
